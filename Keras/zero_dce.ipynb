{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import wandb; wandb.login()\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init()\n",
    "artifact = run.use_artifact('ivangoncharov/Low Light Enhancement with Zero-DCE/Lol_Dataset:v0', type='dataset')\n",
    "artifact_dir = artifact.download()\n",
    "artifact_path = os.path.join(artifact_dir, \"lol_dataset.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip $artifact_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 16\n",
    "MAX_TRAIN_IMAGES = 400\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE])\n",
    "    image = image / 255.0\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(low_light_images):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((low_light_images))\n",
    "    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_low_light_images = sorted(glob(\"./lol_dataset/our485/low/*\"))[:MAX_TRAIN_IMAGES]\n",
    "val_low_light_images = sorted(glob(\"./lol_dataset/our485/low/*\"))[MAX_TRAIN_IMAGES:]\n",
    "test_low_light_images = sorted(glob(\"./lol_dataset/eval15/low/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data_generator(train_low_light_images)\n",
    "val_dataset = data_generator(val_low_light_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Dataset:\", train_dataset)\n",
    "print(\"Validation Dataset:\", val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"low_light_zero_DCE\", job_type=\"EDA\")\n",
    "\n",
    "table = wandb.Table(columns=[\"Low light\", \"High light\"])\n",
    "\n",
    "for img_path in train_low_light_images[:100]:\n",
    "  lowlight_image = Image.open(img_path)\n",
    "  highlight_image = Image.open(img_path.replace(\"low\", \"high\"))\n",
    "  table.add_data(\n",
    "        wandb.Image(np.array(lowlight_image)),\n",
    "        wandb.Image(np.array(highlight_image)),\n",
    "    )\n",
    "\n",
    "\n",
    "wandb.log({\"Dataset table\": table})\n",
    "\n",
    "wandb.finish()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a91feb76d2cfba618382ccdc2b85d611235fabcd242fa6c0b552577aa957b87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
